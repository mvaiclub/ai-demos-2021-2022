{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Optimization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qA8RRs-yFGSx"
      },
      "source": [
        "from sklearn.datasets import load_digits\n",
        "X, y = load_digits(return_X_y = True) #Load the dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUSjvGWkFkbe"
      },
      "source": [
        "from sklearn.model_selection import train_test_split \n",
        "\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, random_state = 1) #Split the ENTIRE Dataset into two categories - Train and Test\n",
        "Xtrain, Xval, ytrain, yval = train_test_split(Xtrain, ytrain) #Split the Training Set (split in previous line) into a smaller training set and an intermediate \"validation\" set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "LZdGAxEX3RVx",
        "outputId": "72ef765a-ea77-4bd9-b911-e6d7033c6256"
      },
      "source": [
        "'''\n",
        "Visualization of Data - Note: we skipped this because we all know what numbers look like & time reasons,\n",
        "but it is a Good Idea to do this!\n",
        "'''\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20,4))\n",
        "for index, (image, label) in enumerate(zip(X[0:5], y[0:5])):\n",
        " plt.subplot(1, 5, index + 1)\n",
        " plt.imshow(np.reshape(image, (8,8)))\n",
        " plt.title('Training: %i\\n' % label, fontsize = 20)\n",
        "\n",
        "for i in range(5):\n",
        "  print(f'Answer to Image {i}: {y[i]}')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Answer to Image 0: 0\n",
            "Answer to Image 1: 1\n",
            "Answer to Image 2: 2\n",
            "Answer to Image 3: 3\n",
            "Answer to Image 4: 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpytjBYKGIpU",
        "outputId": "2215243c-abce-4502-c8f0-4ded3e2cbb7a"
      },
      "source": [
        "'''\n",
        "Hard way ... before Cross Validation - \n",
        "Brute Force a range of possibilities and use a BUUUNCH of variables to store the optimal parameters !! \n",
        "'''\n",
        "from sklearn.linear_model import LogisticRegression #Importing the model\n",
        "from sklearn.metrics import accuracy_score #Evaluation\n",
        "\n",
        "bestAcc = -1 #Define a global max to store the best parameters - accuracy and the C value which we are \"tuning\"\n",
        "bestC = 0\n",
        "\n",
        "for i in range(-20, 20):\n",
        "    model = LogisticRegression(C = 10**i, max_iter = 1000, solver='liblinear')\n",
        "    model.fit(Xtrain, ytrain) #Train on the training set\n",
        "\n",
        "    predY = model.predict(Xval) #Evaluate on a validation set\n",
        "    acc = accuracy_score(yval, predY)\n",
        "    if acc > bestAcc:\n",
        "        bestAcc = acc\n",
        "        bestC = 10 ** i\n",
        "\n",
        "#We find the best model depending on the Best Accuracy on Validation Set\n",
        "model = LogisticRegression( C = 10 ** bestC, max_iter=1000, solver='liblinear')\n",
        "model.fit(Xtrain, ytrain)\n",
        "\n",
        "#Then we evaluate the model on the last dataset - the test set (We can skip the validation set since we already use it to find the best model)\n",
        "predY = model.predict(Xtest)\n",
        "from sklearn.metrics import classification_report\n",
        "print('Results on the test set:')\n",
        "print(classification_report(ytest, predY))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results on the test set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.96      0.98        53\n",
            "           1       0.98      0.98      0.98        42\n",
            "           2       1.00      0.95      0.97        41\n",
            "           3       0.98      0.94      0.96        52\n",
            "           4       0.92      1.00      0.96        47\n",
            "           5       0.93      0.95      0.94        39\n",
            "           6       1.00      1.00      1.00        43\n",
            "           7       1.00      0.96      0.98        48\n",
            "           8       0.95      0.97      0.96        37\n",
            "           9       0.92      0.96      0.94        48\n",
            "\n",
            "    accuracy                           0.97       450\n",
            "   macro avg       0.97      0.97      0.97       450\n",
            "weighted avg       0.97      0.97      0.97       450\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPUwy6_NIEQ-",
        "outputId": "0c36f281-6cf6-4f75-f162-9096d9289d6f"
      },
      "source": [
        "'''\n",
        "Easy Method: K Fold Cross Validation\n",
        "'''\n",
        "from sklearn.model_selection import GridSearchCV #Cross Validation / Neural Network Tuning\n",
        "\n",
        "model = LogisticRegression(C = 100 , max_iter= 1000, solver='liblinear')\n",
        "parameters = {'C' : [10**i for i in range(-20,20)] } \n",
        "bestModel = GridSearchCV(model, parameters) \n",
        "bestModel.fit(Xtrain, ytrain) #Train / Search for the best \n",
        "print(bestModel.best_params_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'C': 0.01}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGdUgO7KKNdi",
        "outputId": "e542a3c4-673b-4142-9fb6-83908e21d49f"
      },
      "source": [
        "'''\n",
        "Evaluating the best model from KFold\n",
        "Note: With KFold, we do NOT need an intermediate validation set to prevent overfitting. KFold already splits it into its own 'validation set'\n",
        "'''\n",
        "\n",
        "predY = bestModel.predict(Xtest)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print('Results on the test set:')\n",
        "print(classification_report(ytest, predY))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results on the test set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98        53\n",
            "           1       1.00      0.95      0.98        42\n",
            "           2       0.98      1.00      0.99        41\n",
            "           3       1.00      0.94      0.97        52\n",
            "           4       0.96      1.00      0.98        47\n",
            "           5       0.90      0.95      0.92        39\n",
            "           6       0.98      1.00      0.99        43\n",
            "           7       0.98      0.98      0.98        48\n",
            "           8       0.97      0.92      0.94        37\n",
            "           9       0.94      0.96      0.95        48\n",
            "\n",
            "    accuracy                           0.97       450\n",
            "   macro avg       0.97      0.97      0.97       450\n",
            "weighted avg       0.97      0.97      0.97       450\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}